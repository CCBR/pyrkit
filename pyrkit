#!/usr/bin/env bash

# pyrkit: a tool to archive and co-locate NGS data with hierarchical metadata
set -euo pipefail

VERSION="0.1.0-beta"

# Functions
function err() { cat <<< "$@" 1>&2; }
function fatal() { cat <<< "$@" 1>&2; exit 1; }
function log() { echo -e "[$(date +'%Y-%m-%dT%H:%M:%S%z')]: $@"; }
function abspath() { readlink -e "$1"; }
function parser() {
# Parses command-line args using argparse.bash
# @INPUT "$@" = user command-line arguments

ARGPARSE_DESCRIPTION="A tool to archive and co-locate NGS data with structured metadata"
ARGPARSE_EPILOG="Version $VERSION"
argparse "$@" << EOF || exit 0
# Required arguments group
required = parser.add_argument_group('Required Arguments')
optional = parser.add_argument_group('Optional Arguments')
required.add_argument('-i', '--input-directory', required=True, type=str,
                    help='Required local directory containing files (raw data and output files) \
                    to upload into object storage (HPC DME). This path is the output directory \
                    of a pipeline. Example: -i /data/projects/ccbr123/RNA/')
required.add_argument('-o', '--output-vault', required=True, type=str,
                    help='Required vault in HPC DME to upload and archive local \
                    input files and metadata. This vault represents the root HPC DME \
                    path to archive the data located in --input-directory into object \
                    storage. CCBR has two main vaults: /CCBR_EXT_Archive and /CCBR_Archive. \
                    /CCBR_EXT_Archive is for storing any public data such as data or results \
                    from dbGap, SRA, GEO or EBI. /CCBR_Archive is for storing any other data \
                    such as data from internal (SF) and external sequencing providers \
                    (NovoGene, GeneDx, Macrogen, Genentech). Example: -o /CCBR_Archive')
required.add_argument('-r', '--request-template', required=True, type=str,
                    help='Required Project Request Template. The project request template is \
                    an excel spreadsheet sent out to the requestor to capture information about \
                    a project or experiment. This excel file is parsed to capture any required \
                    metadata for instantiating a PI-, Project-, and Sample-level collection hierarchy \
                    in HPC DME. Example: -t experiment_metadata.xlsx')
required.add_argument('-m', '--multiqc-directory', required=True, type=str,
                    help='Required MultiQC Output Directory. This directory is created by \
                    MultiQC. It contains several text files which are generated by MultiQC \
                    as it builds the report. These files are parsed to \
                    attach quality-control metadata to each Sample-level collection. \
                    Example: -m /data/projects/ccbr123/RNA/multiqc_data/')
# Optional arguments group
optional.add_argument('-p', '--project-id', type=str,
                    help='Optional Project ID. This is a unique identifer or alias tied to \
                    a request to internally distinguish a project. This could be a CCBR/NCBR/NAS project \
                    ID. Example: -p ccbr-123')
optional.add_argument('-h', '--help', action='help', default=argparse.SUPPRESS,
                    help='Display help message and exit')
optional.add_argument('--version', action='version',
                    version='%(prog)s $VERSION', help="Display version information and exit")
EOF
}


function provided() {
  # Checks to see if key,value pairs exist
  # @INPUT $1 = name of user provided argument
  # @INPUT $2 = value of user provided argument
  # @CALLS fatal() if value is empty string or NULL

  if [[ -z "${2:-}" ]]; then
     fatal "Fatal: Failed to provide value to '${1}'!";
  fi
}


function clean(){
  # Finds the base name of the sample
  # @INPUT $1 = From optional basename argument
  # @RETURN $bname = cleaned base name (PATH and EXT removed)

  local bname=${1:-}
  local exts=("_1.fastq" "_2.fastq" ".R1.fastq" ".R2.fastq" "_R1.fastq" "_R2.fastq")

  if [[ -z "$bname" ]]; then
     bname="${Arguments[r1]}"  # Determine base name from R1 input
  fi

  # Remove PATH and .gz extension
  bname=$(basename $bname | sed 's/.gz$//g')

  # Clean remaining extensions (MateInfo + )
  for ext in "${exts[@]}"; do
    if [[ $bname == *${ext} ]]; then
      bname=$(echo "$bname" | sed "s@$ext\$@@")
      break # only remove one extension
    fi
  done

  echo "$bname"
}


function require(){
  # Requires an executable is in $PATH, as a last resort it will attempt to load
  # the executable or dependency as a module
  # @INPUT $@ = List of dependencies or executables to check

  for exe in "${@}"; do
    # Check if executable is in $PATH
    command -V ${exe} &> /dev/null && continue;
    # Try to load exe as lua module
    module load ${exe} &> /dev/null || \
      fatal "Failed to find or load '${exe}', not installed on target system."
  done
}


function init(){
  # Intializes a list of directories
  # @INPUT $@ = List of directories

  for d in "${@}"; do
    mkdir -p ${d} || fatal "Failed to initialize '${d}' directory";
  done
}


function lint(){
  # Lints user-provided project request template (experiment_metadata.xlsx)
  # Check for basic errors and if user provided all the require metadata
  # See --request-template or $REQUEST_TEMPLATE in help for more information
  # @INPUT $1 = PATH to pyrkit/src/lint.py program
  # @INPUT $2 = Project Request Template files to parse and lint
  # @INPUT $3 = Output Directory
  python ${1} ${2} ${3}
}


function _get_inner_distances(){
  # Parses Inner Distance Maxmia from RSeQC output files
  # @INPUT $1 = Input Directory or pipeline working directory (i.e. $INPUT_DIRECTORY)
  # @INPUT $2 = MultiQC Output Directory
  # @INPUT $3 = Parsed Inner Distance Output file

  # Performant approach to checking if glob exists using a Bash built-in function
  if compgen -G "${1}/STAR_files/*.Aligned.sortedByCoord.out.inner_distance_freq.txt" > /dev/null; then
    echo -e "Sample\tInner_Dist_Maxima" > ${2}/${3} || fatal "Failed to write to MultiQC Directory ${2}"
    # Get Inner Distance Maxima from RSeQC Output files
    for f in ${1}/STAR_files/*.Aligned.sortedByCoord.out.inner_distance_freq.txt; do
      sample=$(basename $f | sed 's/^output.//' | sed 's/.p2.Aligned.sortedByCoord.out.inner_distance_freq.txt$//');
      inner_dist_maxima=$(sort -k3,3nr "$f" | awk -F '\t' 'NR==1{print $1}');
      echo -e "${sample}\t${inner_dist_maxima}";
    done >> ${2}/${3}
  fi
}


function _get_median_tin(){
  # Parses RSeQC Median TIN (transcript integrity number) from output files
  # @INPUT $1 = Input Directory or pipeline working directory (i.e. $INPUT_DIRECTORY)
  # @INPUT $2 = MultiQC Output Directory
  # @INPUT $3 = Parsed medTIN Output file

  # Performant approach to checking if glob exists using a Bash built-in function
  if compgen -G "${1}/STAR_files/*.summary.txt" > /dev/null; then
    echo -e "Sample\tmedian_tin" > ${2}/${3} || fatal "Failed to write to MultiQC Directory ${2}"
    # Parse medTIN from RSeQC tin.py output files
    cut -f1,3 "${1}"/STAR_files/*.summary.txt | \
      grep -v '^Bam_file' | \
      sed 's/.p2.Aligned.sortedByCoord.out.dmark.bam//g' | \
      awk -F '\t' '{printf "%s\t%.3f\n", $1,$2}' >> ${2}/${3}
  fi
}


function parse(){
  # Parse additional output files that MultiQC does not automatically parse
  # @INPUT $1 = Input Directory or pipeline working directory (i.e. $INPUT_DIRECTORY)
  # @INPUT $2 = MultiQC Directory (i.e. $MULTIQC_DIRECTORY)

  # Parse Addtional QC metadata from logfiles
  _get_inner_distances "${1}" "${2}" "mqc_rseqc_inner_distance_plot_Percentages_parsed.txt"
  _get_median_tin "${1}" "${2}" "rseqc_median_tin.txt"
}

function main(){
  # Parses cli args using argparse.bash and input files to extract metadata for upload
  # Initializes upload directory representing DME heirarchy
  # Generates collection and dataobject metadata based on inputs
  # @INPUT "$@" = command-line arguments
  # @CALLS parser(), initialize()

  # Check for version flag
  case ${1:-} in
    --version) echo "$(basename $0) $VERSION" && exit 0;;
  esac

  # pyrkit home directory or installation location
  repohome=$(abspath $(dirname  "$0"))

  # Enable argparse parsing within bash
  source $(dirname $0)/src/argparse.bash || \
    fatal "Fatal: Failed to locate argparse.bash in ${repohome}!"

  # Parse command-line arguments with argparse
  if [ $# -eq 0 ]; then parser -h; fi  # Display usage, user did not provide any args
  parser "${@}"

  # Exported Argparse variables
  #echo "Input Directory: $INPUT_DIRECTORY"
  #echo "Output DME Vault: $OUTPUT_VAULT"
  #echo "Request Template: $REQUEST_TEMPLATE"
  #echo "MultiQC HOME: $MULTIQC_DIRECTORY"
  #echo "Project ID: $PROJECT_ID"

  # Base directory for all intermediate output files
  output="${INPUT_DIRECTORY%/}/DME"

  init output
  require git jq python/3.5
  lint "${repohome}/src/lint.py" "${REQUEST_TEMPLATE}" "${output}"
  parse "${INPUT_DIRECTORY%/}" "${MULTIQC_DIRECTORY%/}"

}

# Main: check usage, parse args, extract metadata from inputs and generate upload heirarchy
main "$@"
